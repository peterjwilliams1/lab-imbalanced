{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0.0    912597\n",
       "1.0     87403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud['fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2.207101</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>1.626798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>19.872726</td>\n",
       "      <td>2.683904</td>\n",
       "      <td>2.778303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2.914857</td>\n",
       "      <td>1.472687</td>\n",
       "      <td>0.218075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4.258729</td>\n",
       "      <td>0.242023</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>58.108125</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                57.877857                        0.311140   \n",
       "1                10.829943                        0.175592   \n",
       "2                 5.091079                        0.805153   \n",
       "3                 2.247564                        5.600044   \n",
       "4                44.190936                        0.566486   \n",
       "...                    ...                             ...   \n",
       "999995            2.207101                        0.112651   \n",
       "999996           19.872726                        2.683904   \n",
       "999997            2.914857                        1.472687   \n",
       "999998            4.258729                        0.242023   \n",
       "999999           58.108125                        0.318110   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                             1.945940              1.0        1.0   \n",
       "1                             1.294219              1.0        0.0   \n",
       "2                             0.427715              1.0        0.0   \n",
       "3                             0.362663              1.0        1.0   \n",
       "4                             2.222767              1.0        1.0   \n",
       "...                                ...              ...        ...   \n",
       "999995                        1.626798              1.0        1.0   \n",
       "999996                        2.778303              1.0        1.0   \n",
       "999997                        0.218075              1.0        1.0   \n",
       "999998                        0.475822              1.0        0.0   \n",
       "999999                        0.386920              1.0        1.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                   0.0           0.0    0.0  \n",
       "1                   0.0           0.0    0.0  \n",
       "2                   0.0           1.0    0.0  \n",
       "3                   0.0           1.0    0.0  \n",
       "4                   0.0           1.0    0.0  \n",
       "...                 ...           ...    ...  \n",
       "999995              0.0           0.0    0.0  \n",
       "999996              0.0           0.0    0.0  \n",
       "999997              0.0           1.0    0.0  \n",
       "999998              0.0           1.0    0.0  \n",
       "999999              0.0           1.0    0.0  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_values = fraud[\"fraud\"].value_counts()\n",
    "fraud_values.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fraud.drop(columns = [\"fraud\"])\n",
    "target = fraud[\"fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958848"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = pd.DataFrame(X_train_scaled, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud[\"fraud\"] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = train[train[\"fraud\"] == 1]\n",
    "no_fraud = train[train[\"fraud\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_oversampled = resample(fraud, \n",
    "                                    replace=True, \n",
    "                                    n_samples = len(no_fraud),\n",
    "                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497411</th>\n",
       "      <td>-0.379457</td>\n",
       "      <td>-0.063770</td>\n",
       "      <td>0.865567</td>\n",
       "      <td>-2.727751</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486663</th>\n",
       "      <td>-0.248797</td>\n",
       "      <td>-0.196377</td>\n",
       "      <td>1.072128</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523633</th>\n",
       "      <td>2.504378</td>\n",
       "      <td>0.078404</td>\n",
       "      <td>-0.589029</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242005</th>\n",
       "      <td>1.292336</td>\n",
       "      <td>-0.215586</td>\n",
       "      <td>-0.613149</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479734</th>\n",
       "      <td>1.009879</td>\n",
       "      <td>0.347920</td>\n",
       "      <td>1.630074</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749994</th>\n",
       "      <td>-0.271304</td>\n",
       "      <td>-0.208484</td>\n",
       "      <td>-0.374619</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>-0.031413</td>\n",
       "      <td>-0.180884</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>-0.353614</td>\n",
       "      <td>-0.191219</td>\n",
       "      <td>-0.567566</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>-0.362189</td>\n",
       "      <td>0.145233</td>\n",
       "      <td>-0.411778</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>-0.338696</td>\n",
       "      <td>0.279381</td>\n",
       "      <td>-0.326019</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1368910 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "497411           -0.379457                       -0.063770   \n",
       "486663           -0.248797                       -0.196377   \n",
       "523633            2.504378                        0.078404   \n",
       "242005            1.292336                       -0.215586   \n",
       "479734            1.009879                        0.347920   \n",
       "...                    ...                             ...   \n",
       "749994           -0.271304                       -0.208484   \n",
       "749995           -0.031413                       -0.180884   \n",
       "749996           -0.353614                       -0.191219   \n",
       "749998           -0.362189                        0.145233   \n",
       "749999           -0.338696                        0.279381   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "497411                        0.865567        -2.727751   1.362858   \n",
       "486663                        1.072128         0.366602  -0.733752   \n",
       "523633                       -0.589029         0.366602  -0.733752   \n",
       "242005                       -0.613149         0.366602  -0.733752   \n",
       "479734                        1.630074         0.366602   1.362858   \n",
       "...                                ...              ...        ...   \n",
       "749994                       -0.374619         0.366602  -0.733752   \n",
       "749995                        0.003855         0.366602  -0.733752   \n",
       "749996                       -0.567566         0.366602  -0.733752   \n",
       "749998                       -0.411778         0.366602  -0.733752   \n",
       "749999                       -0.326019         0.366602  -0.733752   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "497411        -0.334906      0.733318    1.0  \n",
       "486663        -0.334906      0.733318    1.0  \n",
       "523633        -0.334906      0.733318    1.0  \n",
       "242005        -0.334906      0.733318    1.0  \n",
       "479734        -0.334906      0.733318    1.0  \n",
       "...                 ...           ...    ...  \n",
       "749994        -0.334906      0.733318    0.0  \n",
       "749995        -0.334906      0.733318    0.0  \n",
       "749996        -0.334906      0.733318    0.0  \n",
       "749998        -0.334906      0.733318    0.0  \n",
       "749999        -0.334906     -1.363665    0.0  \n",
       "\n",
       "[1368910 rows x 8 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_over = pd.concat([fraud_oversampled, no_fraud])\n",
    "train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_plt = train_over[\"fraud\"].value_counts()\n",
    "fraud_plt.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = train_over.drop(columns = [\"fraud\"])\n",
    "y_train_over = train_over[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.57      0.95      0.71     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.78      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599872</th>\n",
       "      <td>0.557032</td>\n",
       "      <td>-0.181282</td>\n",
       "      <td>-0.534772</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113452</th>\n",
       "      <td>-0.319045</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399822</th>\n",
       "      <td>-0.052513</td>\n",
       "      <td>-0.168727</td>\n",
       "      <td>-0.393818</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506320</th>\n",
       "      <td>-0.188947</td>\n",
       "      <td>-0.117482</td>\n",
       "      <td>-0.553521</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249149</th>\n",
       "      <td>-0.361801</td>\n",
       "      <td>-0.215489</td>\n",
       "      <td>-0.551409</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530043</th>\n",
       "      <td>0.028696</td>\n",
       "      <td>-0.210992</td>\n",
       "      <td>-0.580739</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>2.985909</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319624</th>\n",
       "      <td>0.052764</td>\n",
       "      <td>-0.070256</td>\n",
       "      <td>-0.537348</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184373</th>\n",
       "      <td>-0.358415</td>\n",
       "      <td>-0.213357</td>\n",
       "      <td>-0.240279</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635804</th>\n",
       "      <td>-0.141757</td>\n",
       "      <td>-0.184911</td>\n",
       "      <td>-0.045541</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145725</th>\n",
       "      <td>-0.359327</td>\n",
       "      <td>-0.164989</td>\n",
       "      <td>-0.467070</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65545 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "599872            0.557032                       -0.181282   \n",
       "113452           -0.319045                        0.875800   \n",
       "399822           -0.052513                       -0.168727   \n",
       "506320           -0.188947                       -0.117482   \n",
       "249149           -0.361801                       -0.215489   \n",
       "...                    ...                             ...   \n",
       "530043            0.028696                       -0.210992   \n",
       "319624            0.052764                       -0.070256   \n",
       "184373           -0.358415                       -0.213357   \n",
       "635804           -0.141757                       -0.184911   \n",
       "145725           -0.359327                       -0.164989   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "599872                       -0.534772         0.366602   1.362858   \n",
       "113452                       -0.360927         0.366602  -0.733752   \n",
       "399822                       -0.393818         0.366602   1.362858   \n",
       "506320                       -0.553521         0.366602  -0.733752   \n",
       "249149                       -0.551409         0.366602  -0.733752   \n",
       "...                                ...              ...        ...   \n",
       "530043                       -0.580739         0.366602  -0.733752   \n",
       "319624                       -0.537348         0.366602   1.362858   \n",
       "184373                       -0.240279         0.366602  -0.733752   \n",
       "635804                       -0.045541         0.366602  -0.733752   \n",
       "145725                       -0.467070         0.366602  -0.733752   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "599872        -0.334906     -1.363665    0.0  \n",
       "113452        -0.334906      0.733318    0.0  \n",
       "399822        -0.334906     -1.363665    0.0  \n",
       "506320        -0.334906     -1.363665    0.0  \n",
       "249149        -0.334906     -1.363665    0.0  \n",
       "...                 ...           ...    ...  \n",
       "530043         2.985909     -1.363665    0.0  \n",
       "319624        -0.334906     -1.363665    0.0  \n",
       "184373        -0.334906      0.733318    0.0  \n",
       "635804        -0.334906     -1.363665    0.0  \n",
       "145725        -0.334906      0.733318    0.0  \n",
       "\n",
       "[65545 rows x 8 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fraud_undersampled = resample(no_fraud, \n",
    "                                    replace=False, \n",
    "                                    n_samples = len(fraud),\n",
    "                                    random_state=0)\n",
    "no_fraud_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599872</th>\n",
       "      <td>0.557032</td>\n",
       "      <td>-0.181282</td>\n",
       "      <td>-0.534772</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113452</th>\n",
       "      <td>-0.319045</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399822</th>\n",
       "      <td>-0.052513</td>\n",
       "      <td>-0.168727</td>\n",
       "      <td>-0.393818</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506320</th>\n",
       "      <td>-0.188947</td>\n",
       "      <td>-0.117482</td>\n",
       "      <td>-0.553521</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249149</th>\n",
       "      <td>-0.361801</td>\n",
       "      <td>-0.215489</td>\n",
       "      <td>-0.551409</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530043</th>\n",
       "      <td>0.028696</td>\n",
       "      <td>-0.210992</td>\n",
       "      <td>-0.580739</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>2.985909</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319624</th>\n",
       "      <td>0.052764</td>\n",
       "      <td>-0.070256</td>\n",
       "      <td>-0.537348</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184373</th>\n",
       "      <td>-0.358415</td>\n",
       "      <td>-0.213357</td>\n",
       "      <td>-0.240279</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635804</th>\n",
       "      <td>-0.141757</td>\n",
       "      <td>-0.184911</td>\n",
       "      <td>-0.045541</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145725</th>\n",
       "      <td>-0.359327</td>\n",
       "      <td>-0.164989</td>\n",
       "      <td>-0.467070</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65545 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "599872            0.557032                       -0.181282   \n",
       "113452           -0.319045                        0.875800   \n",
       "399822           -0.052513                       -0.168727   \n",
       "506320           -0.188947                       -0.117482   \n",
       "249149           -0.361801                       -0.215489   \n",
       "...                    ...                             ...   \n",
       "530043            0.028696                       -0.210992   \n",
       "319624            0.052764                       -0.070256   \n",
       "184373           -0.358415                       -0.213357   \n",
       "635804           -0.141757                       -0.184911   \n",
       "145725           -0.359327                       -0.164989   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "599872                       -0.534772         0.366602   1.362858   \n",
       "113452                       -0.360927         0.366602  -0.733752   \n",
       "399822                       -0.393818         0.366602   1.362858   \n",
       "506320                       -0.553521         0.366602  -0.733752   \n",
       "249149                       -0.551409         0.366602  -0.733752   \n",
       "...                                ...              ...        ...   \n",
       "530043                       -0.580739         0.366602  -0.733752   \n",
       "319624                       -0.537348         0.366602   1.362858   \n",
       "184373                       -0.240279         0.366602  -0.733752   \n",
       "635804                       -0.045541         0.366602  -0.733752   \n",
       "145725                       -0.467070         0.366602  -0.733752   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "599872        -0.334906     -1.363665    0.0  \n",
       "113452        -0.334906      0.733318    0.0  \n",
       "399822        -0.334906     -1.363665    0.0  \n",
       "506320        -0.334906     -1.363665    0.0  \n",
       "249149        -0.334906     -1.363665    0.0  \n",
       "...                 ...           ...    ...  \n",
       "530043         2.985909     -1.363665    0.0  \n",
       "319624        -0.334906     -1.363665    0.0  \n",
       "184373        -0.334906      0.733318    0.0  \n",
       "635804        -0.334906     -1.363665    0.0  \n",
       "145725        -0.334906      0.733318    0.0  \n",
       "\n",
       "[65545 rows x 8 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fraud_undersampled = resample(no_fraud, \n",
    "                                    replace=False, \n",
    "                                    n_samples = len(fraud),\n",
    "                                    random_state=0)\n",
    "no_fraud_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599872</th>\n",
       "      <td>0.557032</td>\n",
       "      <td>-0.181282</td>\n",
       "      <td>-0.534772</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113452</th>\n",
       "      <td>-0.319045</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399822</th>\n",
       "      <td>-0.052513</td>\n",
       "      <td>-0.168727</td>\n",
       "      <td>-0.393818</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506320</th>\n",
       "      <td>-0.188947</td>\n",
       "      <td>-0.117482</td>\n",
       "      <td>-0.553521</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249149</th>\n",
       "      <td>-0.361801</td>\n",
       "      <td>-0.215489</td>\n",
       "      <td>-0.551409</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>-1.363665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749929</th>\n",
       "      <td>-0.398318</td>\n",
       "      <td>-0.209213</td>\n",
       "      <td>4.715708</td>\n",
       "      <td>-2.727751</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749945</th>\n",
       "      <td>-0.165074</td>\n",
       "      <td>-0.210172</td>\n",
       "      <td>0.845348</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749962</th>\n",
       "      <td>-0.344992</td>\n",
       "      <td>0.407557</td>\n",
       "      <td>3.652250</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749978</th>\n",
       "      <td>-0.141487</td>\n",
       "      <td>-0.050178</td>\n",
       "      <td>3.784941</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>-0.733752</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>-0.283479</td>\n",
       "      <td>-0.212796</td>\n",
       "      <td>0.936948</td>\n",
       "      <td>0.366602</td>\n",
       "      <td>1.362858</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.733318</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131090 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "599872            0.557032                       -0.181282   \n",
       "113452           -0.319045                        0.875800   \n",
       "399822           -0.052513                       -0.168727   \n",
       "506320           -0.188947                       -0.117482   \n",
       "249149           -0.361801                       -0.215489   \n",
       "...                    ...                             ...   \n",
       "749929           -0.398318                       -0.209213   \n",
       "749945           -0.165074                       -0.210172   \n",
       "749962           -0.344992                        0.407557   \n",
       "749978           -0.141487                       -0.050178   \n",
       "749997           -0.283479                       -0.212796   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "599872                       -0.534772         0.366602   1.362858   \n",
       "113452                       -0.360927         0.366602  -0.733752   \n",
       "399822                       -0.393818         0.366602   1.362858   \n",
       "506320                       -0.553521         0.366602  -0.733752   \n",
       "249149                       -0.551409         0.366602  -0.733752   \n",
       "...                                ...              ...        ...   \n",
       "749929                        4.715708        -2.727751   1.362858   \n",
       "749945                        0.845348         0.366602   1.362858   \n",
       "749962                        3.652250         0.366602  -0.733752   \n",
       "749978                        3.784941         0.366602  -0.733752   \n",
       "749997                        0.936948         0.366602   1.362858   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "599872        -0.334906     -1.363665    0.0  \n",
       "113452        -0.334906      0.733318    0.0  \n",
       "399822        -0.334906     -1.363665    0.0  \n",
       "506320        -0.334906     -1.363665    0.0  \n",
       "249149        -0.334906     -1.363665    0.0  \n",
       "...                 ...           ...    ...  \n",
       "749929        -0.334906      0.733318    1.0  \n",
       "749945        -0.334906      0.733318    1.0  \n",
       "749962        -0.334906      0.733318    1.0  \n",
       "749978        -0.334906      0.733318    1.0  \n",
       "749997        -0.334906      0.733318    1.0  \n",
       "\n",
       "[131090 rows x 8 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_under = pd.concat([no_fraud_undersampled, fraud])\n",
    "train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under = train_under.drop(columns = [\"fraud\"])\n",
    "y_train_under = train_under[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.57      0.95      0.71     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.78      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_2 = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred_2, y_true = y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.2 in /Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/peterwilliams/Anaconda3/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 1,sampling_strategy=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm,y_train_sm = sm.fit_resample(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.57      0.95      0.71     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.78      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
